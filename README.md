# ConST: Cross-modal Contrastive Learning for Speech Translation 


This is an implementation of NAACL 2022 paper *"Cross-modal Contrastive Learning for Speech Translation"* (read paper [here](https://arxiv.org/abs/2205.02444)). 
The implementation based on [fairseq](https://github.com/pytorch/fairseq) codebase.

**CONTRIBUTION:**
You are also more than welcomed to test our code on your machines, and report feedbacks on results, bugs and performance!


## ✏️ Citation
```
@InProceedings{ye2022cross,
  author    = {Rong Ye and Mingxuan Wang and Lei Li},
  booktitle = {Proc. of NAACL},
  title     = {Cross-modal Contrastive Learning for Speech Translation },
  year      = {2022}
}
```
